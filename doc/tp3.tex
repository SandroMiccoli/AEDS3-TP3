
%	Documentação do Trabalho Prático 3 de AEDSIII
%	@Sandro Miccoli
%
%	* Você pode identificar erros de grafia através do seguinte comando linux:
%		aspell --encoding="utf-8" -c -t=tex --lang="pt_BR" tp2.tex
%

\documentclass[12pt]{article}
\usepackage{sbc-template}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{subfigure}
\usepackage{times,amsmath,epsfig}
\usepackage{graphicx,url}
 \makeatletter
 \newif\if@restonecol
 \makeatother
 \let\algorithm\relax
 \let\endalgorithm\relax
\graphicspath{{./data/}}
\usepackage[lined,algonl,ruled]{algorithm2e}
\usepackage{multirow}
\usepackage[brazil]{babel}
\usepackage[utf8]{inputenc}
\usepackage{listings}

\usepackage{alltt}
\renewcommand{\ttdefault}{txtt}

\sloppy

\title{TRABALHO PRÁTICO 3: \\ Memória Virtual}

\author{Sandro Miccoli - 2009052409 - smiccoli@dcc.ufmg.br}

\address{Departamento de Ciência da Computação -- Universidade Federal de Minas Gerais (UFMG)\\
\\
\today}


\begin{document}

\maketitle

\begin{resumo}
Este relatório descreve como foi implementado uma versão simplificada de um simulador de memória virtual (SMV). Será descrito como foi modelado o problema, e como cada política de reposição de páginas funciona. Finalmente será detalhado a análise de complexidade dos algoritmos e uma análise de cada política de acordo com a especificação do trabalho, e, por último, uma breve conclusão do trabalho implementado.
\end{resumo}

\section{INTRODUÇÃO}

    A memória virtual foi inicialmente criada para possibilitar a um programa ser executado em um computador com uma quantidade de memória principal (física) menor que o tamanho de todo o espaço do utilizado pelo próprio programa. Ou seja, o espaço ocupado pelas instruções, dados e pilha de execução de um programa pode ser maior que o espaço em memória principal disponível.

    Memória virtual, é uma técnica que usa a memória secundária como uma cache para armazenamento secundário. Houve duas motivações principais: permitir o compartilhamento seguro e eficiente da memória entre vários programas e remover os transtornos de programação de uma quantidade pequena e limitada na memória principal. \cite{wikimv}

    O objetivo principal do trabalho é implementar uma versão simplificada de um sistema de memória virtual (SMV), pois usaremos apenas um nível de paginação, sem caches ou otimizações. Quando houver a necessidade de reposição de páginas, foram utilizadas três políticas de reposição:

    \begin{itemize}
    \item \textbf{FIFO (FirstIn, FirstOut)} - A página que está residade a mais tempo é escolhida para remoção.
    \item \textbf{LRU (Least Recently Used)} - A página acessada a mais tempo deve ser escolhida para remoção.
    \item \textbf{LFU (Least Frequently Used)} - A página com a menor quantidade de acessos deve ser escolhida para remoção.
    \end{itemize}


	O restante deste relatório é organizado da seguinte forma. A Seção~\ref{modelagem} descreve como foi feita a modelagem do problema e o armazenamento das páginas virtuais. A Seção \ref{solucao_proposta} descreve como foi feito a manipulação das páginas da memória e detalhes das políticas de reposição. A Seção~\ref{implementacao} trata de detalhes específicos da implementação do trabalho: quais os arquivos utilizados; como é feita a compilação e execução; além de detalhar o formato dos arquivos de entrada e saída. A Seção~\ref{avaliacao_experimental} contém a análise de desempenho de cada uma das políticas de reposição. A Seção~\ref{conclusao} conclui o trabalho.


\section{MODELAGEM}
\label{modelagem}



\section{SOLUÇÃO PROPOSTA}
\label{solucao_proposta}

\subsection{Algoritmos implementados}

\begin{itemize}
 \item \begin{large}\textit{}\end{large}\\
 \subitem \textbf{Descrição:}
 \subitem \textbf{Parâmetros:}
 \subitem \textbf{Complexidade:} $O(n)$, onde $n$ é .
\end{itemize}

\vspace{0.2 true cm}

\begin{itemize}
 \item \begin{large}\textit{}\end{large}\\
 \subitem \textbf{Descrição:}
 \subitem \textbf{Parâmetros:}
 \subitem \textbf{Complexidade:} $O(n^2)$, onde $n$ é o .
\end{itemize}

\vspace{0.2 true cm}


\section{IMPLEMENTAÇÃO}
\label{implementacao}

\subsection{Código}

\subsubsection{Arquivos .c}

\begin{itemize}
\item \textbf{tp3.c} Arquivo principal do programa. Lê os arquivos de entrada, calcula os \textit{page faults} pra cada política e escreve o resultado em um arquivo de saída.
\item \textbf{lista.c} TAD da uma lista duplamente encadeada. Contém funções de manipulação (criação, inserção, remoção e liberação de memória), e também de impressão e cópia.
\item \textbf{smv.c} Contém a implementação das políticas de reposição FIFO, LRU, LFU.
\end{itemize}

\subsubsection{Arquivos .h}

\begin{itemize}
\item \textbf{lista.h} TAD da uma lista duplamente encadeada. Contém a definição da estrutura e das funções.
\item \textbf{smv.h} Contém a definição das políticas de reposição FIFO, LRU, LFU.
\end{itemize}

\subsection{Compilação}

O programa deve ser compilado através do compilador GCC através dos seguintes comandos

Para programação dinâmica:
\begin{footnotesize}
\begin{verbatim}
gcc -Wall -Lsrc src/tp3.c src/lista.c src/arquivos.c src/smv.c -o tp3 \end{verbatim}
\end{footnotesize}

Ou através do comando $make$.

\subsection{Execução}

A execução do programa tem como parâmetros:
\begin{itemize}
\item Um arquivo de entrada contendo várias instâncias a serem simuladas.
\item Um arquivo de saída que irá receber a quantidade de \textit{page faults} pra cada política de reposição
\end{itemize}

O comando para a execução do programa é da forma:

\begin{footnotesize}
\begin{verbatim} ./tp3 <arquivo_de_entrada> <arquivo_de_saída>\end{verbatim}
\end{footnotesize}


\subsubsection{Formato da entrada}

A primeira linha do arquivo de entrada contém o valor \textit{k} de instâncias que o arquivo contém. As $k$ instâncias são definidas em duas linhas cada uma. A primeira linha contem três inteiros: o tamanho em bytes da memória física, o tamanho em bytes de cada página, e o número N de acessos. A linha seguinte contém N inteiros representando as N posições da memória virtual acessadas sequencialmente.

A seguir um arquivo de entrada de exemplo:

\begin{verbatim}
1
8 4 10
0 2 4 2 10 1 0 0 6 8
\end{verbatim}

\subsubsection{Formato da saída}

O arquivo de saída consiste em $k$ linhas, cada uma representando o resultado de uma instância. Cada linha contém um inteiro que representa o número de falhas utilizando FIFO, LRU e LFU, necessariamente nessa ordem. Um exemplo é mostrado abaixo:

\begin{verbatim}
6 5 5
\end{verbatim}


\section{AVALIAÇÃO EXPERIMENTAL}
\label{avaliacao_experimental}

Para testar os algoritmos foi feito o seguinte: um script foi criado que, utilizando um dicionário de aproximadamente 2000 palavras, geraria uma sequência de palavras, concatenadas ou não, para testar cada tipo de cenário.

Foi realizado uma série de testes, com entradas crescentes, da maneira que é explicado nas próximas seções.

\subsection{Máquina utilizada}
\label{maquina}

Segue especificação da máquina utilizada para os testes:
\begin{verbatim}
model name:     Intel(R) Core(TM) i3 CPU       M 330  @ 2.13GHz
cpu MHz:        933.000
cache size:     3072 KB
MemTotal:       3980124 kB
\end{verbatim}


\subsection{Testes}
\label{testes}

Então foi pensado em cinco testes a serem executados, um com apenas uma palavra pra ser testada, outro com 5 palavras concatenadas, um com 10 palavras concatenadas, um com 50 palavras concatenadas e, por último, um teste com 100 palavras concatenadas. Assim teríamos testes com palavras relativamente pequenas e com uma série de caracteres relativamente grandes. Assim poderíamos ver o comportamento de cada paradigma para tanto entradas pequenas quando grandes.

O gráfico que será mostrado em cada teste mostra especificamente a quantidade de caracteres (em porcentagem) a mais que o algoritmo guloso teve de inserir que o algoritmo de programação dinâmica. Assim podemos fazer uma análise entre a solução não-ótima e a solução ótima.

Dentro de cada subseção será dado um exemplo de entrada para cada teste e será detalhado melhor as características de cada um.

\subsubsection{Testes pequenos - Uma palavra}
\label{pequeno}

A quantidade média de caracteres neste teste ficou entre aproximadamente $10$. A seguir um exemplo das palavras utilizadas no teste:

\begin{verbatim}
abbreviations
abandoned
youthfulness
...
\end{verbatim}


    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.6\textwidth]{umapalavra.png}
        \caption{Uma palavra - Quantidade de caracteres a mais (em \%)}
        \label{umapalavra}
    \end{figure}

    Na Figura \ref{umapalavra} é perceptível que a grande maioria dos testes não houve diferença entre a solução gulosa e a solução ótima. Porém, quando houve, a diferença de caracteres cresceu bastante, chegando até a $200\%$.

    Para não alterar demais a visualização do gráfico, um resultado foi removido pois a diferença de caracteres era de $800\%$; mas, de uma série de 200 palavras testadas, apenas uma que teve esse comportamento. Isso ocorreu quando o algoritmo de programação dinâmica teve de inserir apenas uma letra e o guloso inseriu 9.


\subsubsection{Testes médios - Cinco palavras concatenadas}
\label{medio}

Na Figura \ref{cincopalavras} pode-se ver o resultado do teste que utilizou uma série de palavras concatenadas, neste caso, cinco palavras. Cada instância ficou com aproximadamente $30$ até $40$ caracteres. A seguir um exemplo das palavras usadas no teste:

\begin{verbatim}
abatedabnormallywondrousxeroxingzero
deifiedwonabolishmentsabbottzenith
yankeewizardwoefulabaseswrangle
...
\end{verbatim}


    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.6\textwidth]{cincopalavras2.png}
        \caption{Cinco palavras - Quantidade de caracteres a mais (em \%)}
        \label{cincopalavras}
    \end{figure}

\subsubsection{Testes médios - Dez palavras concatenadas}
\label{medio10}

Na Figura \ref{dezpalavras} consta o resultado do teste que utilizou uma série de caracteres que eram formados por palavras concatenadas umas nas outras, neste caso, 10 palavras no total. Cada instância ficou com aproximadamente $60$ até $80$ caracteres. A seguir um exemplo das palavras usadas no teste:

\begin{verbatim}
woveyugoslavianyoungsterreferyuridevovedwonderabashingaboveyellowed
wontwritesabaseszuluwrestyeayesterdayabbreviatingzoologicallyzone
yorktownwrittenaberrationsaibohphobiaababawrappedwolffaberrantablewrote
...
\end{verbatim}


    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.6\textwidth]{dezpalavras3.png}
        \caption{Dez palavras - Quantidade de caracteres a mais (em \%)}
        \label{dezpalavras}
    \end{figure}


\subsubsection{Testes grandes - Cinquenta palavras concatenadas}
\label{grande50}

Na Figura \ref{cinquentapalavras} aumentamos a quantidade de palavras concatenadas para cinquenta. Neste teste não iremos mostrar as palavras concatenadas, mas cada uma ficou com $350$ até $450$ caracteres.

    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.6\textwidth]{cinquentapalavras.png}
        \caption{Cinquenta palavras - Quantidade de caracteres a mais (em \%)}
        \label{cinquentapalavras}
    \end{figure}

\subsubsection{Testes grandes - Cem palavras concatenadas}
\label{grande100}

Na Figura \ref{cempalavras}, no último teste, concatenamos cem palavras. Não iremos mostrar as palavras concatenadas, mas cada uma ficou com uma média de $900$ caracteres.

    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.6\textwidth]{cempalavras.png}
        \caption{Cem palavras - Quantidade de caracteres a mais (em \%)}
        \label{cempalavras}
    \end{figure}

\subsection{Resultado}

	Como é possível perceber pela série de testes na última seção, quanto maior a cadeia de caracteres a ser computada pelos algoritmos, mais homogênea e regular a diferença entre cada solução fica. Nos primeiros teste, de apenas uma palavra \ref{pequeno}, e de 5 palavras \ref{medio}, a variação é gritante. No primeiro varia de $0\%$ até $800\%$, no segundo a variação diminui mas ainda é relativamente grande. Podemos ver na Figura \ref{cincopalavras}, que a quantidade de caracteres vai de aproximadamente $15\%$ para $100\%$.

	Nos últimos testes a curva de variação de caracteres vai se tornando cada vez mais estável. No teste com dez palavras concatenadas, na Figura \ref{dezpalavras}, a variação vai de aproximadamente $25\%$ para $75\%$. Mas quando os caracteres vão para a casa das centenas e milhares, essa variação se torna cada vez menor, se localizando em torno dos $60\%$, $70\%$.


\section{CONCLUSÃO}
\label{conclusao}

    Os dois algoritmos implementados solucionam o problema do palíndromo apresentado. O primeiro algoritmo, utilizando o paradigma de programação dinâmica, possui solução ótima, ou seja, sempre encontrará o melhor resultado. Já o algoritmo guloso, possui solução não-ótima, pois toma as decisões que julga ser melhor naquele momento específico, porém sem considerar vários outros aspectos do problema.

    Foi visto na Avaliação Experimental, que quanto maior a cadeia de caracteres, mais constante ficava a diferença entre as soluções ótima e não-ótima. Claro que a solução ótima ainda conseguia resolver o problema com uma média de $60\%$ a menos de caracteres inseridos, mas ainda assim era um resultado que não era esperado. Acreditava que a solução não-ótima do algoritmo guloso teria um rendimento muito pior.

    Caso fosse acatar o resultado do teste \ref{pequeno}, poderia dizer que o teto observável para a quantidade de caracteres a ser inseridos seria $800\%$, porém esse foi um único caso dentre centenas de outros testados. Observando os resultados dos testes maiores, poderia dizer que o teto observável ficaria em torno de $75\%$.

    O problema de gerar palíndromos de forma eficiente foi solucionado com sucesso. Além disso, duas soluções, uma ótima e uma não-ótima, foram implementadas, obtendo um bom rendimento nos inúmeros testes realizados. Nos testes comparativos foi possível perceber a diferença gritante entre uma solução ótima e uma não-ótima.

\bibliographystyle{sbc}
\bibliography{tp3}

\end{document}
